import math
import matplotlib.pyplot as plt
import numpy as np
import random
from collections import defaultdict
from scipy.stats import entropy, beta


def expected_reward(a, b):
    return a / (a + b)


def uncertainty_bonus(a, b):
    """
    Variance of beta distribution
    """
    return (a * b) / ((a + b) ** 2 * (a + b + 1))


def compute_q(a, b, sigma):
    return expected_reward(a, b) + sigma * uncertainty_bonus(a, b)


def softmax(i, all_q, beta=10):
    if math.exp(beta * all_q[i]) / sum([math.exp(beta * q) for q in all_q]) > 1:
        true_prob = math.exp(beta * all_q[i]) / sum([math.exp(beta * q) for q in all_q])
        raise ValueError(f"Softmax values do not lie on simplex: {true_prob}")
    return math.exp(beta * all_q[i]) / sum([math.exp(beta * q) for q in all_q])


def trials(trial_num=180):
    """
    Four bandit options, each with fixed reward probability and with beliefs modeled via Beta-Binomial
    """

    bandit_probs = {
        "A": 0.8,
        "B": 0.6,
        "C": 0.4,
        "D": 0.2,
    }

    trial_outcomes = defaultdict(list)

    for i in range(trial_num):
        trial_outcomes["A"].append(1 if random.uniform(0, 1) < bandit_probs["A"]
                                   else 0)
        trial_outcomes["B"].append(1 if random.uniform(0, 1) < bandit_probs["B"]
                                   else 0)
        trial_outcomes["C"].append(1 if random.uniform(0, 1) < bandit_probs["C"]
                                   else 0)
        trial_outcomes["D"].append(1 if random.uniform(0, 1) < bandit_probs["D"]
                                   else 0)

    return trial_outcomes


def get_entropy(dist):
    """
    Compute entropy over action probabilities.
    A proportional, proxy measure of pupil diameter.
    """
    return entropy(dist)


def entropy_series(bandit_trials, bonus=1):
    """
    Calculate entropy over time based on uncertainty bonus
    """

    # Initialize beliefs as Beta(1,1) distribution
    beliefs = defaultdict(list)
    beliefs["A"].append((1, 1))
    beliefs["B"].append((1, 1))
    beliefs["C"].append((1, 1))
    beliefs["D"].append((1, 1))

    bandit_names = list(zip(bandit_trials.keys()))
    observations = list(bandit_trials.values())
    observations = zip(observations[0], observations[1], observations[2], observations[3])

    # Store bandit outcomes
    entropy_hist = []
    for bandit_idx, bandit_set in enumerate(observations):
        # List of action q-scores for each bandit
        action_space = []

        if bandit_idx == 0:
            action_space.extend([compute_q(1, 1, sigma=bonus)] * 4)

        else:
            for i, obs in enumerate(bandit_set):
                # Update Beta distribution
                bandit = bandit_names[i][0]
                a, b = beliefs[bandit][-1]
                if obs == 1:
                    a = a + 1
                else:
                    b = b + 1

                beliefs[bandit].append((a, b))
                action_space.append(compute_q(a, b, sigma=bonus))

        prob_dist = [softmax(i, action_space) for i in range(len(action_space))]
        entropy_hist.append(get_entropy(prob_dist))

    return entropy_hist, beliefs


def plot_betas(x, beta_A, beta_B, beta_C, beta_D, t=10):

    y_1 = beta.pdf(x, a=beta_A[t][0], b=beta_A[t][1])
    y_2 = beta.pdf(x, a=beta_B[t][0], b=beta_B[t][1])
    y_3 = beta.pdf(x, a=beta_C[t][0], b=beta_C[t][1])
    y_4 = beta.pdf(x, a=beta_D[t][0], b=beta_D[t][1])
    plt.plot(x, y_1, label="Beta A")
    plt.plot(x, y_2, label="Beta B")
    plt.plot(x, y_3, label="Beta C")
    plt.plot(x, y_4, label="Beta D")
    plt.legend()
    plt.title(f"Betas at T={t}")
    plt.tight_layout()
    plt.savefig(f"betas{t}.png")
    plt.show()


def temperature_demo():
    cat = [random.uniform(0, 1) for _ in range(20)]
    cat = np.array(cat) / sum(cat)
    plt.bar(range(20), cat)
    plt.title("Hot Dist")
    plt.xticks([])
    plt.savefig(f"cold.png")
    plt.show()
    scaled = [softmax(i, cat, beta=100) for i, c in enumerate(cat)]
    plt.bar(range(20), scaled)
    plt.title("Cold Dist")
    plt.xticks([])
    plt.savefig(f"hot.png")
    plt.show()


def main():
    bandit = trials()
    # Baseline experiment with primarily exploitation
    exploit_entropy, exploit_beliefs = entropy_series(bandit, bonus=1)
    # Repeat on same trials but with more exploration
    explore_entropy, explore_beliefs = entropy_series(bandit, bonus=50)
    entropy_25, _ = entropy_series(bandit, bonus=25)
    entropy_100, _ = entropy_series(bandit, bonus=100)
    entropy_no_bonus, _ = entropy_series(bandit, bonus=0)

    avg_exploit, avg_explore = sum(exploit_entropy) / len(exploit_entropy), sum(explore_entropy) / len(explore_entropy)
    print("Avg Exploit Sigma=1", avg_exploit)
    print("Avg Explore Sigma=25", sum(entropy_25) / len(entropy_25))
    print("Avg Explore Sigma=50", avg_explore)
    print("Avg Explore Sigma=100", sum(entropy_100) / len(entropy_100))
    print("Avg No Bonus", sum(entropy_no_bonus) / len(entropy_no_bonus))

    plt.style.use('seaborn')
    plt.plot(entropy_no_bonus, label="No Bonus")
    plt.plot(exploit_entropy, label="Exploit")
    plt.plot(explore_entropy, label="Explore")
    plt.annotate("Entropy Maxed at Unif", (0, explore_entropy[0]))
    plt.xlabel("Trial")
    plt.ylabel("Entropy $\propto$ Pupil Diam")
    plt.title("Exploration vs. Exploitation")
    plt.legend()
    plt.tight_layout()
    plt.savefig("entropy.png")
    plt.show()

    plt.figure()
    x = np.linspace(-1, 2, 5000)
    beta_A, beta_B, beta_C, beta_D = explore_beliefs["A"], \
                                     explore_beliefs["B"], \
                                     explore_beliefs["C"], \
                                     explore_beliefs["D"]

    plot_betas(x, beta_A, beta_B, beta_C, beta_D, 15)
    plot_betas(x, beta_A, beta_B, beta_C, beta_D, 150)

    temperature_demo()

if __name__ == "__main__":
    main()
